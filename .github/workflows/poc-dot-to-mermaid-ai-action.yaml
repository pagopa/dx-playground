name: Convert dot to Mermaid with Inference

# Ref. https://github.com/actions/ai-inference
# Ref. https://docs.github.com/en/github-models/use-github-models/integrating-ai-models-into-your-development-workflow

on:
  workflow_dispatch:
  push:
    branches:
      - feat-poc-ai-graph-generation

jobs:
  dot-to-mermaid:
    runs-on: ubuntu-latest
    permissions:
      models: read
      contents: read
    steps:
      - name: Checkout PR
        uses: actions/checkout@v4

      - name: Generate Prompt
        run: |
          PROMPT=$(cat <<'EOF'
          You are an expert in converting Terraform-generated Graphviz DOT diagrams into clear, human-friendly Mermaid diagrams.

          Requirements:
          1. **Output only valid Mermaid syntax** (no prose).
          2. **Orientation**: Use `graph RL` (right-to-left).
          3. **Subgraphs**: Group nodes into logical clusters with meaningful titles.
          4. **Naming**:  
            - Strip Terraform resource prefixes (`azurerm_`, `data.`) and use title-case labels (e.g. `Key Vault Certificate`, `API Management Service`).  
            - For DNS entries, include both zone and record type (`A Record - apim.azure-api.net`).
          5. **Connections**:  
            - Draw arrows only once per relationship.  
            - Label edges only if it adds clarity (otherwise omit labels).
          6. **Clean Up**:  
            - Remove any standalone â€œmanagement lockâ€ or â€œdiagnosticâ€ nodes that donâ€™t have outgoing or incoming edgesâ€”unless theyâ€™re essential.
            - Collapse any trivial one-node subgraphs into their parent group.

          Here is the original DOT code:
          ```dot
          EOF
          )

          DOT_CONTENT=$(<./infra/resources/dev/graph.dot)

          echo "$PROMPT
          $DOT_CONTENT" > prompt.txt

          cat prompt.txt

      - name: Verify Models permission via a ping
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          STATUS=$(
            curl -o /dev/null -s -w "%{http_code}" \
              -X POST \
              -H "Authorization: Bearer $GITHUB_TOKEN" \
              -H "Content-Type: application/json" \
              -d '{"model":"openai/gpt-4o","messages":[{"role":"user","content":"Ping"}]}' \
              https://models.github.ai/inference/chat/completions
          )
          echo "Inference ping returned HTTP $STATUS"
          if [ "$STATUS" -ne 200 ]; then
            echo "ðŸš¨ models:read permission is missing or AI is not enabled"
            exit 1
          fi

      - name: Run AI Inference with Prompt File
        id: inference
        uses: actions/ai-inference@v1.1.0
        with:
          prompt-file: './prompt.txt'
          max-tokens: 4096
          model: openai/gpt-4o
          token: ${{ secrets.GITHUB_TOKEN }}


      - name: Use Response File
        run: |
          echo "Response saved to: ${{ steps.inference.outputs.response-file }}"
          cat "${{ steps.inference.outputs.response-file }}"

      - name: Upload Artifact
        uses: actions/upload-artifact@0b2256b8c012f0828dc542b3febcab082c67f72b # v4.3.4
        with:
          name: "bundle-mermaid"
          path: ${{ steps.inference.outputs.response-file }}
          if-no-files-found: error
          retention-days: 7