name: Convert dot to Mermaid with Inference

# Ref. https://github.com/actions/ai-inference
# Ref. https://docs.github.com/en/github-models/use-github-models/integrating-ai-models-into-your-development-workflow

on:
  workflow_dispatch:
  # push:
  #   branches:
  #     - feat-poc-ai-graph-generation

jobs:
  dot-to-mermaid:
    runs-on: ubuntu-latest
    permissions:
      models: read
      contents: read
    steps:
      - name: Checkout PR
        uses: actions/checkout@v4

      - name: Generate Prompt
        run: |
          cat > prompt.txt <<EOF
          You are an expert in converting Terraform-generated Graphviz DOT diagrams into clear, human-friendly Mermaid diagrams.

          â€”RULESâ€”
          1. Output **only** valid Mermaid code, nothing else.
          2. Start with `graph RL`.
          3. Use safe alphanumeric node IDs (CamelCase or snake_case) and assign human-readable labels in `["â€¦"]`.
          4. Automatically group nodes with shared prefixes into `subgraph` blocks. Each block must be:
            subgraph Group Title
            direction RL
            NodeA[â€œLabel Aâ€]
            NodeB[â€œLabel Bâ€]
            end
          5. After subgraphs, list every edge once:
            NodeA â€“> NodeB
          6. Strip technical prefixes (`azurerm_`, `data.`) and convert to Title Case for labels.
          7. Exclude isolated nodes or merge single-node groups into their parent.

          â€”DOT INPUT STARTâ€”
          \`\`\`dot
          $(cat ./infra/resources/dev/graph.dot)
          \`\`\`
          EOF

          cat prompt.txt

      # - name: Verify Models permission via a ping
      #   env:
      #     GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      #   run: |
      #     STATUS=$(
      #       curl -o /dev/null -s -w "%{http_code}" \
      #         -X POST \
      #         -H "Authorization: Bearer $GITHUB_TOKEN" \
      #         -H "Content-Type: application/json" \
      #         -d '{"model":"openai/gpt-4o","messages":[{"role":"user","content":"Ping"}]}' \
      #         https://models.github.ai/inference/chat/completions
      #     )
      #     echo "Inference ping returned HTTP $STATUS"
      #     if [ "$STATUS" -ne 200 ]; then
      #       echo "ðŸš¨ models:read permission is missing or AI is not enabled"
      #       exit 1
      #     fi

      - name: Run AI Inference with Prompt File
        id: inference
        uses: actions/ai-inference@v1.1.0
        with:
          prompt-file: './prompt.txt'
          max-tokens: 4096
          model: openai/gpt-4o
          token: ${{ secrets.GITHUB_TOKEN }}


      - name: Use Response File
        run: |
          echo "Response saved to: ${{ steps.inference.outputs.response-file }}"
          cat "${{ steps.inference.outputs.response-file }}"

      - name: Upload Artifact
        uses: actions/upload-artifact@0b2256b8c012f0828dc542b3febcab082c67f72b # v4.3.4
        with:
          name: "bundle-mermaid"
          path: ${{ steps.inference.outputs.response-file }}
          if-no-files-found: error
          retention-days: 7