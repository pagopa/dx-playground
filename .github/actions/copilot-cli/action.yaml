name: "AWS Bedrock AI Runner"
description: "Execute prompts using AWS Bedrock and return the results"
author: "PagoPA DX Team"

inputs:
  prompt:
    description: "The prompt to send to AWS Bedrock"
    required: true
  model:
    description: "The Bedrock model ID (e.g., anthropic.claude-3-5-sonnet-20240620-v1:0, anthropic.claude-3-haiku-20240307-v1:0)"
    required: false
    default: "qwen.qwen3-coder-30b-a3b-v1:0"
  aws-region:
    description: "AWS region for Bedrock"
    required: false
    default: "eu-central-1"
  max-tokens:
    description: "Maximum tokens in the response"
    required: false
    default: "4096"
  temperature:
    description: "Temperature for response generation (0.0-1.0)"
    required: false
    default: "1.0"

outputs:
  result:
    description: "The response from AWS Bedrock"
    value: ${{ steps.run-bedrock.outputs.result }}
  success:
    description: "Whether the command executed successfully (true/false)"
    value: ${{ steps.run-bedrock.outputs.success }}

runs:
  using: "composite"
  steps:
    - name: Call AWS Bedrock
      id: run-bedrock
      shell: bash
      env:
        PROMPT: ${{ inputs.prompt }}
        MODEL: ${{ inputs.model }}
        AWS_REGION: ${{ inputs.aws-region }}
        MAX_TOKENS: ${{ inputs.max-tokens }}
        TEMPERATURE: ${{ inputs.temperature }}
      run: |
        set -e

        echo "Calling AWS Bedrock with model: $MODEL in region: $AWS_REGION"

        # Escape prompt for JSON
        PROMPT_JSON=$(echo "$PROMPT" | jq -Rs .)

        # Prepare request body based on model type
        if [[ "$MODEL" == anthropic.claude* ]]; then
          # Claude models format
          REQUEST_BODY=$(cat <<EOF
        {
          "anthropic_version": "bedrock-2023-05-31",
          "max_tokens": $MAX_TOKENS,
          "temperature": $TEMPERATURE,
          "messages": [
            {
              "role": "user",
              "content": $PROMPT_JSON
            }
          ]
        }
        EOF
        )
        elif [[ "$MODEL" == amazon.titan* ]]; then
          # Titan models format
          REQUEST_BODY=$(cat <<EOF
        {
          "inputText": $PROMPT_JSON,
          "textGenerationConfig": {
            "maxTokenCount": $MAX_TOKENS,
            "temperature": $TEMPERATURE
          }
        }
        EOF
        )
        else
          # Default format for other models
          REQUEST_BODY=$(cat <<EOF
        {
          "inputText": $PROMPT_JSON,
          "textGenerationConfig": {
            "maxTokenCount": $MAX_TOKENS,
            "temperature": $TEMPERATURE
          }
        }
        EOF
        )
        fi

        # Call Bedrock API
        RESPONSE=$(aws bedrock-runtime invoke-model \
          --model-id "$MODEL" \
          --region "$AWS_REGION" \
          --body "$REQUEST_BODY" \
          --cli-binary-format raw-in-base64-out \
          /dev/stdout 2>/tmp/bedrock_error.log)

        if [ $? -ne 0 ]; then
          echo "success=false" >> $GITHUB_OUTPUT
          ERROR_MSG=$(cat /tmp/bedrock_error.log)
          echo "result<<EOF" >> $GITHUB_OUTPUT
          echo "AWS Bedrock error: $ERROR_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          exit 1
        fi

        # Extract result based on model type
        if [[ "$MODEL" == anthropic.claude* ]]; then
          RESULT=$(echo "$RESPONSE" | jq -r '.content[0].text')
        elif [[ "$MODEL" == amazon.titan* ]]; then
          RESULT=$(echo "$RESPONSE" | jq -r '.results[0].outputText')
        else
          RESULT=$(echo "$RESPONSE" | jq -r '.results[0].outputText // .content[0].text // .outputText')
        fi

        echo "success=true" >> $GITHUB_OUTPUT
        echo "result<<EOF" >> $GITHUB_OUTPUT
        echo "$RESULT" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT

        echo "AWS Bedrock call successful"

branding:
  icon: "cpu"
  color: "orange"
